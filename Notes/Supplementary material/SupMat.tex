\documentclass[journal, onecolumn]{IEEEtran}

\usepackage{graphicx}
\usepackage{bbm}
\usepackage{amsfonts,amssymb,amsmath,amsthm}
\usepackage{type1cm,eso-pic,color}
\usepackage{mathrsfs} 
\usepackage{mathpazo}
\usepackage[scaled=.95]{helvet}
\usepackage{courier}
\usepackage{xr}
\usepackage{xspace}
\usepackage{etoolbox}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{algorithm,algorithmic}

\input{../mydefs}

\title{An Approach for the Reduction of Boundary Effects in Time-Frequency Representations:\\ Part II}

\author{Adrien~Meynard, %~\IEEEmembership{Member,~IEEE,}
        Hau-Tieng~Wu
\thanks{A. Meynard and H.-T. Wu are with the Department
of Mathematics, Duke University, Durham,
NC, 27708 USA e-mail: adrien.meynard@duke.edu}}

\newtheorem{remark}{Remark}

\begin{document}
\maketitle

\setcounter{equation}{8}
\setcounter{figure}{3}


\section{Proof of Lemma~1}
\label{ap:lm.error}
We have:
\begin{align}
\dfrac1K\bX\bX^T &= \underbrace{\dfrac1K\bZ\bZ'+\sigma^2\bI}_{\defeq S^{(0)}} + \bE^{(0)} \\
\dfrac1K\bY\bX^T &= \underbrace{\dfrac1K\bZ\bZ^T +\sigma^2\bD}_{\defeq S^{(1)}}+ \bE^{(1)} \ ,
\end{align}
where $\bE^{(a)} = \sigma\bE_1^{(a)} + \sigma^2\bE_2^{(a)}$ with:
\[
\bE_1^{(a)}[m,m'] = \dfrac1K\sum_{k=0}^{K-1} \bz[N_0+m+a+k]\bw[N_0+m'+k] + \bw[N_0+m+a+k]\bz[N_0+m'+k]\ ,
\]
and
\[
\bE_2^{(a)}[m,m'] =  \dfrac1K\sum_{k=0}^{K-1} \bw[N_0+m+a+k]\bw[N_0+m'+k] - \delta_{(m+a)m'}\ ,
\]
with $a\in\{0,1\}$.
\begin{remark}
The matrices $\bE^{(0)}$ and $\bE^{(1)}$ are said to be error matrices because:
\begin{align*}
\EE\{\bE^{(0)}\} &= \EE\{\bE_1^{(0)}\} = \EE\{\bE_2^{(0)}\} = \bzero \\
\EE\{\bE^{(1)}\} &= \EE\{\bE_1^{(1)}\} = \EE\{\bE_2^{(1)}\} = \bzero\ .
\end{align*}
\end{remark}
Thus:
\begin{align*}
\tilde\bA &= (\bS^{(1)}+\bE^{(1)})(\bS^{(0)}+\bE^{(0)})^\inv \\
\bA_0&=\bS^{(1)}{\bS^{(0)}}^\inv
\end{align*}
Then:
\begin{align}
\nonumber
\bh^{(\ell)} &= \balpha^{(\ell)} - \balpha^{(\ell)}_0 \\
\nonumber
&= \be_M^T\left(\tilde\bA^\ell-\tilde\bA_0^\ell\right) \\
&= \be_M^T\left(\left((\bS^{(1)}+\bE^{(1)})(\bS^{(0)}+\bE^{(0)})^\inv\right)^\ell- \tilde\bA_0^\ell\right)\ .
\label{eq:error.vec}
\end{align}
Thus, the randomness of $\bh^{(\ell)}$ is completely originating from the random vector $\bg\in\RR^{M(M+1)}$ defined as:
\[
\bg = \vec\left(
\begin{pmatrix}
\bE^{(0)} \\
\be_M^T\bE^{(1)}
\end{pmatrix}
\right)\ .
\]
{\color{blue}
Thus, one can write $\bh^{\ell}$ as $\bh^{\ell}=f^{(\ell)}(g)$ where $f^{(\ell)}$ is a deterministic function:
\begin{align*}
f^{(\ell)} : \RR^{M(M+1)} &\to \RR^{M} \\
 \bg &\mapsto \bh^{(\ell)}\ . \\
\end{align*}
Besides, by application of the central limit theorem, the random vector $\bg$ converges in law to a Gaussian random vector:
\[
\sqrt{K}\ \bg \xrightarrow[K\to\infty]{\cD} \cN(\bzero,\bGamma_0)\ .
\]
Then, using Delta method, we have:
\begin{align*}
\sqrt{K}\ \bh^{(\ell)} \xrightarrow[K\to\infty]{\cD} \cN(\bzero,{\bF^{(\ell)}}^T\bGamma_0\bF^{(\ell)})\ ,
\end{align*}
where:
\[
\bF^{(\ell)}[m,m'] = \left.\dfrac{\partial f^{(\ell)}_m}{\partial\bg[m']}\right\vert_{\bg=\bzero}\ .
\]
}

\section{Proof of Theorem~1}
\label{ap:th.error}

\paragraph{Expression of the bias $\bmu$.}
Clearly, $\bmu[n]=0$ when $n\in I$. When $n=N-1+\ell$, we have:
\begin{align*}
\bmu[n] &=  \EE\{\balpha^{(\ell)}\}\bz_{K} + \sigma\EE\{\balpha^{(\ell)}\bw_{K}\} - \bz[n]\\
& = \balpha_0^{(\ell)}\bz_{K} + \EE\{\bh^{(\ell)}\}\bz_{K} + \sigma\EE\{\bh^{(\ell)}\bw_{K}\} - \bz[N-1+\ell]
\end{align*}
Let us first evaluate the expression of $\balpha_0^{(\ell)}\bz_K$. We have:
\begin{align*}
\bS^{(a)}[m,m'] &= \sigma^2\delta_{(m+a)m'}+\sum_{j,j'=1}^J\dfrac{\Omega_j\Omega_{j'}}{K}\sum_{k=0}^{K-1} \cos\left(2\pi \frac{f_j}{\fs}(N_0+m+a+k)\right)\cos\left(2\pi \frac{f_{j'}}{\fs}(N_0+m'+k)\right) \\
&= \sigma^2\delta_{(m+a)m'}+\sum_{j=1}^J\dfrac{\Omega_j^2}{2K}\sum_{k=0}^{K-1} \cos\left(2\pi \frac{f_j}{\fs}(m+a-m')\right) + \cos\left(2\pi \frac{f_j}{\fs}(2k+m+a+m'+2N_0)\right)\\
&= \sigma^2\delta_{(m+a)m'}+\sum_{j=1}^J\left( \dfrac{\Omega_j^2}2\cos\left(2\pi \frac{f_j}{\fs}(m+a-m')\right) + \dfrac{\Omega_j^2}{2K}\underbrace{\sum_{k=0}^{K-1}\cos\left(2\pi \frac{f_j}{\fs}(2k+m+a+m'+2N_0)\right)}_{=0\ \mathrm{because}\ \frac{f_j}\fs=\frac{p'_j}K } \right)\\
&= \sigma^2\delta_{(m+a)m'}+\sum_{j=1}^J\dfrac{\Omega_j^2}2\cos\left(2\pi \frac{f_j}{\fs}(m+a-m')\right)\ .
\end{align*}
Thus, $\bS^{(0)}$ is a circulant matrix and is therefore diagonalizable in the Fourier basis:
\[
\bS^{(0)} = \bU\bLambda^{(0)}\bU^*\ ,
\]
where $\bU[m,m']=\frac1{\sqrt{M}}e^{-2\ii\pi mm'/M}$ and $\bLambda^{(0)} = \mathrm{diag}(\lambda_0^{(0)},\dots,\lambda_{M-1}^{(0)})$ with:
\begin{align*}
\lambda_m^{(0)} &= \sigma^2 + \sum_{j=1}^J\dfrac{\Omega_j^2}2\sum_{q=0}^{M-1} \cos\left(2\pi\frac{f_j}{\fs} q\right) e^{-2\ii\pi qm/M} \\
&= \sigma^2 + \dfrac{M}{4}\sum_{j=1}^J\Omega_j^2(\delta_{m,p_j} + \delta_{m,M-p_j})\ .
\end{align*}
Therefore:
\begin{align*}
{\bS^{(0)}}^\inv  &= \bU{\bLambda^{(0)}}^\inv\bU^*
\end{align*}
which leads to:
\begin{align*}
{\bS^{(0)}}^\inv[m,m']  &= \dfrac1{\sigma^2}\delta_{m,m'}-\sum_{j=1}^J\dfrac{\Omega_j^2}{2\sigma^2(\sigma^2+\Omega_j^2M/4)}\cos\left(2\pi p_j \dfrac{m-m'}{M}\right)\ ,
\end{align*}
and, consequently:
\begin{align}
\nonumber
\tilde\bA_0[m,m']  &= \sum_{q=0}^{M-1} {\bS^{(1)}}[m,q]{\bS^{(0)}}^\inv[q,m'] \\
&= \delta_{m+1,m'} + \sum_{j=1}^J\dfrac{2\Omega_j^2}{\Omega_j^2M+4\sigma^2}\cos\left(2\pi p_j\frac{m'}{M}\right)\delta_{m+1,M}
\label{eq:A0.sine}
\end{align}
Thus:
\begin{align*}
\tilde\balpha_0^{(1)}[m]  &=\sum_{j=1}^J\dfrac{2\Omega_j^2}{\Omega_j^2M+4\sigma^2}\cos\left(2\pi p_j\frac{m}{M}\right) \\
&= \dfrac{2}{M}\sum_{j=1}^J\cos\left(2\pi p_j\frac{m}{M}\right) + o(\sigma)\ .
\end{align*}
Besides, from equation~\eqref{eq:A0.sine}, we have
\begin{align*}
\tilde\bA_0\bz_{K} &= 
\begin{pmatrix}
\bz[N-M+1] \\
\vdots \\
\bz[N-1] \\
\balpha_0^{(1)}\bz_K
\end{pmatrix}
\end{align*}
By induction, we have:
\begin{align*}
\tilde\bA_0^{\ell}\bz_{K} &= 
\begin{pmatrix}
\bz[N-M+\ell] \\
\vdots \\
\bz[N-1] \\
\balpha_0^{(1)}\bz_K \\
\vdots \\
\balpha_0^{(\ell)}\bz_K
\end{pmatrix}
\ .
\end{align*}
Then:
\begin{align}
\nonumber
\balpha_0^{(\ell)}\bz_{K} &= \tilde\balpha_0^{(1)}\tilde\bA_0^{\ell-1}\bz_{K} \\
&=\sum_{m=0}^{M-\ell}\balpha_0^{(1)}[m]\bz[N-M+\ell+m-1]+\sum_{m=M-\ell+1}^{M-1}\balpha_0^{(1)}[m]\balpha_0^{(m-M+\ell)}\bz_K
\label{eq:seq}
\end{align}
But:
\begin{align*}
\balpha_0^{(1)}\bz_{K} &=\sum_{m=0}^{M-1}\balpha_0^{(1)}[m]\bz[N-M+m] \\
&=\sum_{j,j'=1}^J\Omega_{j'}\dfrac{2}{M}\underbrace{\sum_{m=0}^{M-1}\cos\left(2\pi p_j\frac{m}{M}\right)\cos\left(2\pi p_{j'}\dfrac{N+m}{M}\right)}_{=\delta_{j,j'}\frac{M}2\cos\left(2\pi p_j\frac{N}M\right)} + o(\sigma) \\
&= \sum_{j=1}^J\Omega_j\cos\left(2\pi p_j\dfrac{N}{M}\right) + o(\sigma) \\
&= \bz[N] + o(\sigma)
\end{align*}
and, by induction from~\eqref{eq:seq}:
\begin{equation}
\label{eq:alpha0z.sine}
\balpha_0^{(\ell)}\bz_{K} = \bz[N-1+\ell] + o(\sigma)
\end{equation}
Then:
\begin{equation*}
\bmu[N-1+\ell] = \EE\{\bh^{(\ell)}\}\bz_{K} + \sigma\EE\{\bh^{(\ell)}\bw_{K}\} + o(\sigma)\ .
\end{equation*}
{\color{blue}
Besides, from Lemma~1, we have the following results:
\begin{align*}
\EE\{\bh^{(\ell)}\} &\underset{K\to\infty}{=} o\left(\dfrac1{\sqrt{K}}\right)\\
\EE\{\bh^{(\ell)}\bw_{K}\} &\underset{K\to\infty}{=} o\left(\dfrac1{\sqrt{K}}\right)
\end{align*}
Consequently:
\begin{equation*}
\bmu[N-1+\ell] \underset{K\to\infty}{\sim} o(\sigma)\ .
\end{equation*}


\paragraph{Expression of the covariance $\bgamma$.}
Let us segregate the cases.

First, when $(n,n')\in I^2$, we clearly have $\bgamma[n,n']=\sigma^2\delta_{n,m}$. 

Second, we focus on the case where $n=N-1+\ell\geq N$ and $n'=N-1+\lambda\geq N$. Thus:
\begin{align*}  
\bgamma[n,n'] &= \bz_K^T\EE\left\{{\balpha^{(\ell)}}^T\balpha^{(\lambda)}\right\}\bz_K + \sigma\EE\{\balpha^{(\ell)}\bw_K\balpha^{(\lambda)}\}\bz_K+ \sigma\EE\{\balpha^{(\lambda)}\bw_K\balpha^{(\ell)}\}\bz_K \\
& +\sigma^2\EE\{\balpha^{(\ell)}\bw_K\balpha^{(\lambda)}\bw_K\}-\bz[n]\bz[n']-\bz[n]\bmu[n']-\bz[n]\bmu[n'] - \bmu[n]\bmu[n'] \\
&= \bz_K^T\EE\left\{{\bh^{(\ell)}}^T\bh^{(\lambda)}\right\}\bz_K + \balpha_0^{(\ell)}\sigma\EE\{\bw_K\bh^{(\lambda)}\}\bz_K + \sigma\EE\{\bh^{(\ell)}\bw_K\}\bz(n']  \\
&+ \sigma\EE\{\bh^{(\ell)}\bw_K\bh^{(\lambda)}\}\bz_K+ \sigma\EE\{\bh^{(\lambda)}\bw_K\}\bz[n] + \sigma\balpha_0^{(\lambda)}\EE\{\bw_K\bh^{(\ell)}\}\bz_K \\
& + \sigma\EE\{\bh^{(\lambda)}\bw_K\bh^{(\ell)}\}\bz_K+\sigma^2\balpha_0^{(\ell)}\EE\{\bw_K\bh^{(\lambda)}\bw_K\}+\sigma^2\balpha_0^{(\lambda)}\EE\{\bw_K\bh^{(\ell)}\bw_K\} \\
&+\sigma^2\left\langle\balpha^{(\ell)},\balpha^{(\ell)}\right\rangle +\sigma^2\EE\{\bh^{(\ell)}\bw_K\bh^{(\lambda)}\bw_K\} + o(\sigma^2)
\end{align*}
From lemma~1, we have:
To be continued...

Third, we focus on the case where $n=N-1+\ell\geq N$ and $n'\in I$. The case $n\in I$ and $n'=N-1+\lambda$ is directly derived from the current one.
To be continued...
%\begin{align*}
%\bgamma[\ell,\ell] &\leq \dfrac1K\left(\sqrt{\bz_K^T\EE\{{\bu^{(\ell)}}^T\bu^{(\ell)}\}\bz_K} + \sigma\sqrt{\EE\{(\bu^{(\ell)}\bw_K)^2\}}\right)^2 \\
%&\ + \dfrac{2\sigma}{\sqrt{K}}\|\balpha_0^{(\ell)}\|\left(\sqrt{\bz_K^T\EE\{{\bu^{(\ell)}}^T\bu^{(\ell)}\}\bz_K} +\sigma\sqrt{\EE\{(\bu^{(\ell)}\bw_K)^2\}} \right)+ \sigma^2\|\balpha_0^{(\ell)}\|^2 - \bmu[\ell]^2 + o(\sigma^2) \\
%\end{align*}
%
%Then, Isserlis formula gives us:
%\begin{align*}
%\EE\{(\bu^{(\ell)}\bw_K)^2\} &= \sum_{m,m'=0}^{M-1}\EE\{\bu^{(\ell)}[m]\bw_K[m]\bu^{(\ell)}[m']\bw_K[m']\}\\
%&\underset{K\to\infty}{\sim} \sum_{m,m'=0}^{M-1}\EE\{\bu^{(\ell)}[m]\bw_K[m]\}\EE\{\bu^{(\ell)}[m']\bw_K[m']\}+\EE\{\bu^{(\ell)}[m]\bu^{(\ell)}[m']\}\EE\{\bw_K[m]\bw_K[m']\} \\
%&\hspace{30pt}+\EE\{\bu^{(\ell)}[m]\bw_K[m']\}\EE\{\bu^{(\ell)}[m']\bw_K[m]\}\\
%&\leq \Tr(\bGamma^{(\ell)}) + 2\sum_{m,m'=0}^{M-1}\sqrt{\bGamma^{(\ell)}[m,m]\bGamma^{(\ell)}[m',m']}
%\end{align*}
%So:
%\begin{align*}
%\bgamma[\ell,\ell] &\leq \dfrac1K\left(\sqrt{\bz_K^T\bGamma^{(\ell)}\bz_K} + \sigma\sqrt{\Tr(\bGamma^{(\ell)}) + 2\sum_{m,m'=0}^{M-1}\sqrt{\bGamma^{(\ell)}[m,m]\bGamma^{(\ell)}[m',m']}}\right)^2 \\
%&\ + \dfrac{2\sigma}{\sqrt{K}}\|\balpha_0^{(\ell)}\|\left(\sqrt{\bz_K^T\bGamma^{(\ell)}\bz_K} +\sigma\sqrt{\Tr(\bGamma^{(\ell)}) + 2\sum_{m,m'=0}^{M-1}\sqrt{\bGamma^{(\ell)}[m,m]\bGamma^{(\ell)}[m',m']}} \right)+ \sigma^2\|\balpha_0^{(\ell)}\|^2 + o(\sigma^2) \\
%\end{align*}
}

\end{document}